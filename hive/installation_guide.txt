1) Download e extract
	http://ftp.unicamp.br/pub/apache/hive/hive-3.1.2/

2) Configurar variáveis de ambiente no .bashrc
	#HIVE ENVIRONMENT
	export HIVE_HOME="/home/prbpedro/Development/apps/apache-hive-3.1.2-bin"
	export PATH=$PATH:$HIVE_HOME/bin

3) Configurar arquivos nas pastas bin e conf

4) Criar diretórios do hive no hdfs
	hdfs dfs -mkdir /tmp
	hdfs dfs -chmod g+w /tmp
	hdfs dfs -mkdir -p /user/hive/warehouse
	hdfs dfs -chmod g+w /user/hive/warehouse

5) Atualizar biblioteca guava do hive com a do hadoop
	rm $HIVE_HOME/lib/guava-19.0.jar
	cp $HADOOP_HOME/share/hadoop/hdfs/lib/guava-27.0-jre.jar $HIVE_HOME/lib/

6) Remover jar s4jl do hive
	rm /home/prbpedro/Development/apps/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar

7) Fazer download e descompactar derby 
	http://mirror.nbtelecom.com.br/apache/db/derby/db-derby-10.14.2.0/

8) Configurar variáveis de ambiente do derby no .bashrc
	#DERBY ENVIRONMENT
	export DERBY_HOME=/home/prbpedro/Development/apps/db-derby-10.14.2.0-bin
	export PATH=$PATH:$DERBY_HOME/bin
	export CLASSPATH=$CLASSPATH:$DERBY_HOME/lib/derbyclient.jar

9) Copiar jars para lib hadoop e hive
	/home/prbpedro/Development/apps/db-derby-10.14.2.0-bin/lib
		derbyclient.jar
		derbytools.jar
	/home/prbpedro/Development/apps/hadoop-3.3.0/lib
	/home/prbpedro/Development/apps/apache-hive-3.1.2-bin/lib

11) Parar hadoop 
	stop-all.sh

12) Iniciar a base de dados derby do hive
	schematool -dbType derby -initSchema
	startNetworkServer &
	stopNetworkServer &

13) Iniciar hadoop
	start-all.sh

14) Executar o hive
	hive
	hive --service hiveserver2

15) Verificação do metastore
	ij
	ij version 10.14
	ij> connect 'jdbc:derby://localhost:1527/metastore_db;create=true';
	ij> show tables; 


Ref: https://phoenixnap.com/kb/install-hive-on-ubuntu
